\lstset{language=C}
\lstset{
 morekeywords={action,table,control}
}

\section{Introduction}

\todo[inline]{write short introduction}

\section{The Problem}
\todo[inline]{Explain problem of Control Plane Synthesis with example }

\section{Synthesis by Sketching is a Solution}
\todo[inline]{Explain GCL/WP/CEGIS/Sketching formalisms at a very how
  it can be applied to P4 programs }

\todo[inline]{Conclude that this monolithic solution is too slow}

Sketching~\cite{armando-thesis,armando2013sketch} is a program synthesis technology that 
takes high-level insights about the desired system and automatically infers the details.
The input to the synthesis procedure is a partial program (sketch) that has {\em holes}
in place of code fragments.
The task of the synthesizer is to fill up the holes with the right pieces so that the 
result program meets the required specification.  
The algorithm to generate code for the holes of a sketch is counterexample-guided inductive synthesis (CEGIS).
To describe sketching and CEGIS in the context of our problem domain we use the running 
example of Figure~\ref{fig:running-p4}.

\input{running-example}
\input{gcl}

The logical program in Figure~\ref{fig:running-p4}(a) has a pipeline of two match-action 
tables ({\ttfamily L1} and {\ttfamily L2}).
The first table {\ttfamily L1} matches on {\ttfamily src} and sets the packet headers
{\ttfamily smac} and {\ttfamily dst}.
Table {\ttfamily L2} matches on {\ttfamily dst} and sets {\ttfamily out}.
The physical program in Figure~\ref{fig:running-p4}(b) has a single unified table {\ttfamily P}
that matches on {\ttfamily src}, {\ttfamily dst} and sets $\{${\ttfamily smac}, {\ttfamily out}$\}$
and $\{${\ttfamily dst}, {\ttfamily out}$\}$.
Figure~\ref{fig:running-p4}(c) shows the set of rules in the logical tables
(for the sake of simplicity the fields are integer numbers).
A challenging question is to determine if there exist a set of rules for the physical table 
so that after installation of such rules the physical and logical network 
behave exactly the same on every input packet.
To address this challenge, we first convert the tables with their installed rules into programs
in guarded command programming language~\cite{dijkstra1975}.

Figure~\ref{fig:syntax} shows the syntax of the Guarded Command Language (GCL) 
that we use in this paper.
A single guarded command rule is of the form $\IF~{b \to e}~\ENDIF$ where $b$ is a Boolean
condition and $c$ is a command.
There can be multiple guarded commands inside an $\IF$.
When there are more than a single guard equivalent to {\it true},
we pick the first guard and execute its corresponding command 
(note that this interpretation is different from the classical semantics where 
a satisfying guard is picked randomly).
Figure~\ref{fig:encoding} shows the encoding of the logical and physical programs into 
guarded commands.
Assuming that {\ttfamily src}, {\ttfamily dst}, {\ttfamily smac} and {\ttfamily out}
are variables in the program, each guarded command is responsible for a single row 
of the table.
Note that the physical table does not have any rule so its guarded command does not 
change any variable.

We may wonder if the logical and physical programs of Figure~\ref{fig:encoding}
are already equivalent for any incoming packet so there is no need to insert any extra rules.
Formal verification, an important constituent of any synthesis procedure, answers such equivalence queries.
A synthesizer uses formal verification to decide if the current candidate solution is equivalent 
to what the user actually wants.
In the case that the synthesized program is not the right solution, verification stops with a counter-example to show
the reason for inequivalence.
To use formal verification, we need a formal way to represent the semantics of the GCL programs.
In this paper we use the axiomatic semantics~\cite{hoare1969} which uses logic to give meaning to a program.

The basic idea in the axiomatic approach is to use pre- and post-conditions to show the 
meaning of a command $c$.
If the pre-condition $P$ is met, executing the command $c$ ensures that the post-condition $Q$ holds.
In the Hoare triple notation, this is shown as: $\{P\}~c~\{Q\}$.
We often formulate axiomatic semantics using predicate transformation: given a pre-condition (or post-condition)
transform the condition through the program to find the post-condition (or pre-condition).
For example, let's take the first rule of the table {\ttfamily L1} in the logical table.
If we consider the most general condition on the variable {\ttfamily smac} after the
execution of the rule ($x$ is a fresh variable), what is correct the pre-condition on the variables?

\begin{center}
$
\{?\} ~~ \IF~{\mbox{\ttfamily src} = 1 \to \mbox{\ttfamily smac} := 1}~\ENDIF ~~ \{\mbox{\ttfamily smac} = x\}
$ 
\end{center}


In general, there can be many valid pre-conditions for this Hoare triple.
One valid pre-condition can be $\mbox{\ttfamily src} = 2$ which is a packet that
does not take the rule (since {\ttfamily src}$\neq1$) 
so it does not put any restrictions on the general post-condition $\mbox{\ttfamily smac} = x$.
However, such a pre-condition is not general enough and shows only a specific case.
In describing semantics we are normally looking for the most general (or weakest)
pre-conditions for a command. 
In this example, the weakest pre-condition is $\mbox{\ttfamily src}=1\rightarrow x = 1$
which basically says that {\ttfamily src} can get any value but when it is equal to 1
then the value of $x$ must be equal to $1$ as well (since the rule is taken).
For computation of weakest pre-conditions we use a set of deductive rules.
Figure~\ref{fig:table-wp} shows the weakest pre-condition rules for GCL.
To show that the programs in Figure~\ref{fig:encoding} are equivalent or not,
the formal verifier computes the weakest-preconditions (using the given rules) 
of the both programs with respect to a general packet with fresh symbolic fields.
Only if the two conditions are equal for any values of the variables we 
conclude that the programs are equivalent.
The verifier consults a theorem prover to check the equivalence of the these two universally quantified formulae.
Since the programs in Figure~\ref{fig:encoding} are not equivalent, 
the verification engine will return a counter-example packet to show that the 
programs behave differently.
For example, a counter-example is $\{\mbox{\ttfamily src}=0,\mbox{\ttfamily dst}=0\}$.
When inserted into the logical program, the matched actions will update the header values to 
$\{\mbox{\ttfamily out}=1,\mbox{smac}=1\}$.
In the physical program the header values stay the same since there is no rule in the table.

Verification is one of the main modules in the CEGIS algorithm.
The other main module is the inductive synthesizer as Figure~\ref{fig:cegis} shows.
When verification fails and the verifier produces a concrete counter-example,
it passes the counter-example to the inductive synthesis module.
The task of the inductive synthesizer is to create a candidate solution 
(in this case an instantiation of the physical program)
that works correctly for the given counter-example.
The main idea in CEGIS is to make several iterations on verification and 
inductive synthesis until a valid solution is produced.
CEGIS is guaranteed to stop and return a solution in a finite domain but 
it may take several iterations.
We will describe some of the heuristics to reduce the number of iterations in the later
sections.

\input{cegis}

The inductive synthesizer creates a candidate solution for the given input with the help of sketching.
A sketch in our problem domain is a guarded command rule with holes in place of some constants.
For removing the counter-example $\{\mbox{\ttfamily src}=0,\mbox{\ttfamily dst}=0\}$, 
the user may provide the following sketch to the synthesizer.
This sketch is is basically assisting the synthesizer by saying that 
the required rule should match on the guards $\mbox{\ttfamily src}=0\wedge\mbox{\ttfamily dst}=0$
and the synthesis procedure should find the constants for the holes in the updates of the head of the implication.

\[
\begin{aligned}
 &\IF \\
 &~\mbox{\ttfamily src}=0\wedge\mbox{\ttfamily dst}=0 \to \\
 &~~~~\mbox{\ttfamily src}=?_0~;~\mbox{\ttfamily out}=?_1~;~\mbox{\ttfamily smac}=?_2~;~\mbox{\ttfamily dst}=?_3 \\
 &\ENDIF
\end{aligned}
\]

Note that in principle the user can also leave holes in place of $0$ in the guard.
This only makes the space of search for the synthesizer larger.
We do not require smart sketches from the user in our tool but providing them can 
make the process more efficient..

% Example

% - cross product
% - set-read dependencies
% % - backtracking
% % - action data

% a in A and b in  B
% A must set y sometimes

% two logical tables 
% (, src, A,skip).apply();(dst, B, skip).apply()

% A = {(\v -> smac := v)
%   + skip
%   + (\v -> dst := v)}

% B = {(\v -> out := v)
%   + skip}

% L = {(\v1 -> \v2 -> smac := v1; out := v2)
%   + (\v -> smac:=v)
%   + skip
%   + (\v1 -> \v2 -> dst := v1; out:= v2)
%   + (\v -> dst:= v) }

% src |   A         dst | B
% ---------------; -----------
% 1     smac:= 1    1      out :=1
% 2     dst := 1    2      out :=2
% *     skip        *     skip
% ------>

% Logical table encoding : spec
% if
% src = 1 ---> smac := 1
% src = 2 --> dst := 2
% *  ----> skip
% fi;
% if
% dst = 1 ----> out := 1
% dst = 2 ----> out := 2
% *       ---> skip
% fi

% one physical table
% (p, (src,dst), L, skip).apply()

% src  dst  | L
% -------------------
% *     *      skip

% physical sketch:  sketch
% if
% src = ?src /\ dst = ?dst
% ->
%   if
%   (?select_p = 0) ->  smac := ?v1; out := ?v2
%   (?select_p = 1) -> (smac := ?v)
%   .....
%   fi
% * -> skip

% phi = //\\ { x = x' | x in hdrs, x' is fresh}

% sketch' = assign random values to holes in sketch
% Equivalence:
% wp(spec, phi) <=> wp(sketch', phi)
% | Valid -> done
% | CE pkt -> 
% Model-finding:
% [|spec|](pkt) = pkt'
% wp(sketch, pkt') = phi
% ask z3 find model for holes:
% \exists holes  \forall hdrs. pkt /\ phi
% | UNSAT -> fail ``sorry go home''
% | Sat model ->  
% Update:
%   convert ?keys -> keys
%   convert ?select_p -> action choice
%   convert ?vs -> action data

% go to equivalence  
  
\section{Challenges}
\todo[inline]{Describe the technical challenges with this approach with forward pointers to solutions}
\begin{itemize}
\item Programs are big, but control plane APIs are incremental
\item CEGIS loop is clunky
  \begin{itemize}
  \item Many paths to search through
    \begin{itemize} \item candidate map \end{itemize}
  \item One logical rule may correspond to many physical rules
    \begin{itemize} \item symbolic execution to compute membership VCs \end{itemize}
  \item VCs are big
    \begin{itemize}
    \item cormac
    \item hybrid solvers
    \end{itemize}
  \end{itemize}
Abduction -- when does our loop work?
  \begin{itemize}
  \item conditions on action usability
  \item ??dataflow??
  \end{itemize}
\end{itemize}

\section{A Scalable Solution}
\todo[inline]{High level description of the Solution}

\subsection{Syntax}

Our syntactic representation of packet-processing pipelines can be
found in Figure~\ref{fig-syntax}. Notice that it is more or less the
same as the syntax for GCL, except for the additional table
application command $t.\apply$, which indicates that the controller
can install rules that obey the schema $t$ into this table. A table
schema $t$ is a tuple $(s, \overline f, \overline c, d)$, where $s$ is
a unique identifer for the table, $\overline f$ is the sequence of
fields that the table will match on, $\overline c$ is the set of
actions that can be applied, and $d$ is the default action. Just like
in P4, actions are a subset of full commands, namely, they can only be
assignments and sequences.

Our expression sublanguage focuses solely on bitvector arithmetic and
masking operations. The simplest expression is a bitvector literal. We
can write down variables $x$ that are used to represent packet fields
or metadata. We can combine two expressions expressions $e$ and $e'$
into more complicated ones using unsigned arithmetic addition
$e + e'$, unsigned arithmetic subtraction $e - e'$, or bitwise
intersection $e \mask e'$. We could easily add additional arithmetic
and bitvector operators, but these operators suffice for this
exposition.

The language of booleans is standard. We can express falsehood ($0$),
implication ($\Rightarrow$), bitvector equality $(=)$, and comparison
($<$). In what follows, we will use the standard syntactic sugar
encodings of the remaining boolean and comparison operators freely.

\subsection{Semantics}
\begin{figure*}
  \[\begin{array}{lcl}
      \denote{\SKIP}^\tau~(\pkt,\meta)
      &\triangleq
      & (\pkt,\meta) \\
      \denote{f := e}^\tau(\pkt,\meta)
      &\triangleq
      & (\pkt\{f \mapsto \denote{e}(\pkt,\meta)\}, \meta)\\
      \denote{m := e}^\tau(\pkt, \meta)
      &\triangleq
      & (\pkt, \meta\{f \mapsto \denote{e}^\tau(\pkt,\meta)\})\\
      \denote{c_1;c_2}^\tau(\pkt, \meta)
      &\triangleq
      & \denote{c_2}\left(\denote{c_1}^\tau(\pkt, \meta)\right)\\
      \denote{\IF~\ENDIF}^\tau(\pkt, \meta)
      & \triangleq
      & (\pkt, meta) \\
      \denote{\IF~\overline{b \to c}~\ENDIF}^\tau (\pkt,\meta)
      & \triangleq & \begin{cases}
        \denote{c_1}^\tau(\pkt,\meta)& \denote{b_1}^\tau(\pkt, \meta) = 1 \\
        \denote{\IF~b_2 \to c_2 \cdots b_n \to c_n~\ENDIF}^\tau (\pkt,\meta) & \mathit{otherwise}
      \end{cases} \\
      \denote{t.\apply}^\tau(\pkt,\meta)
      & \triangleq
      & \run(\tau(s),\overline f, c_0)(\pkt,\meta) \\\\
      \run(\cdot, \overline f, \overline c, c_0)(\pkt, \meta)
      & \triangleq
      & \denote{c_0}^\tau(\pkt,\meta) \\
      \run(((\overline k, a)\cdot\overline e), \overline f, \overline c,  c_0) (\pkt, meta)
      & \triangleq
      & \begin{cases}
        \denote{c_a}^\tau(\pkt, \meta) & \denote{\overline k = \overline f} (\pkt, \meta) = 1 \\
        \run(\overline e, \overline f,\overline c, c_0) (\pkt, \meta) & \mathit{otherwise} \\
        \end{cases}
    \end{array}
  \]
  \caption{Semantics of pipeline processing programs. The denotations
    of bitvector and boolean expressions are omitted for brevity}
\end{figure*}

In a formal setting, we can model the denotation of packet processing
programs as functions on packets ($\Pkt \to \Pkt$). However, our
commands are not fully executable on their own -- we need to know how
to populate the tables before we know what function the programs
denote. We record the existing table rules in a \emph{table
  instantiation function},
$\tau : \TableName \rightharpoonup \Entry^*$, which maps the name of
table, to a list of the entries that have been inserted by the
controller. A valid entry $(k_1,\ldots, k_n, i) \in \Entry$ in a table
$t$ with keys $f_1, \ldots, f_m$, actions $a_1, \ldots, a_l$ and
default action $a_0$, has $n = m$, and $i \in \{0, \ldots, l\}$, where
each $k_i \in \BitVector$.
\todo[inline]{Incorporate inexact matches}

We also need to consider the packet metadata, which we will encode as
a separate packet, and will not be considered in packet equality.

Most of the cases of our denotational semantics are standard. The
denotation $\SKIP$ is the identity function; assignment $x := e$
updates the metadata $\meta$ or the packet $\pkt$ depending on whether
$x \in \Metadata$ or $x \in \Field$; sequence $c_1;c_2$ first executes
$c_1$ and then executes $c_2$; and selection
$\IF~\overline{b \to c}~\ENDIF$ iterates through the list of guards
$b$, and executes the first $c_i$ for which $b_i$ holds true.

The semantics of table application
$(s, \overline f, \overline c, d).\apply$ is a bit nonstandard, but
very similar to the semantics of selection. We iterate through the
rows $\overline{(\overline k, i)}$ of $\tau(s)$, executing the first
$a_i$ for which
$\denote{\overline f = \overline k}^\tau~\pkt~\meta = 1$. If no such
entry exists then the default action is chosen. Note that the
semantics for a table application are undefined if $\tau(s)$ is
undefined.

The semantics of expressions and booleans are standard, although we
make the assumption the expressions are ``well-typed'', i.e. the
expressions on either side of the operators denote vectors of the same
length. This property is easy to statically check.

\subsection{Edits}

However, the controller doesn't interface with a switch, or a table,
in terms of full instantiations, interacts with the tables in terms of
incremental insertions. There are three kinds of operations that a
controller can take: \emph{insertion}, \emph{deletion}, and
\emph{update}. For the purposes of this paper, we only focus on
insertions, since deletions and assertions require the same mechanisms
as insertion does.

We write an edit $e \in \Edit$ as a pair $(s, \rho)$ with
$s \in \TableName$ and $\rho \in \Entry$, which denotes the insertion
of row $\rho$ into table $s$. Given a table instantiation function
$\tau$, we can write $\tau + e$ to mean the map
$\tau[s \mapsto \tau(s) \append \rho]$. Note that the edit inserts a
row at the end of the sequence of entries, which means it has the
lowest priority (ahead of only the default action).

\todo[inline]{Say something about priority insertion}

\subsection{Predicate Transformer Semantics}

\begin{figure}
  \[
    \begin{array}{lcl}
      \wp_\tau(\SKIP,\phi)
      & \triangleq
      & \phi \\
      \wp_\tau(x := e, \phi)
      & \triangleq
      & \phi[e/x]\\
      \wp_\tau(c_1;c_2, \phi)
      & \triangleq
      & \wp_\tau(c_2, \wp_\tau(c_1, \phi)) \\
      \wp_\tau(\IF~\overline{b \to c}~\ENDIF, \phi)
      & \triangleq
      & (\bigvee_i b_i) \wedge \\
      && \bigwedge_i\left(b_i \wedge \bigwedge_{j=1}^{j-1}\neg b_j\right) \Rightarrow \wp_\tau(c_i, \phi)\\
      \wp_\tau(t.\apply, \phi)
      &\triangleq
      &  \bigwedge_{(\overline{k_i}, i) \in \tau(s)}\hit\left(\tau(s), \overline f, i\right)\Rightarrow \wp(c_i,\phi) \\
      && \wedge \allmiss(\tau,s) \Rightarrow \wp(c_0, \phi) \\
      && \textit{where } t = (s, \overline f, \overline c, c_0) \\
      \hit\left(\overline{\left(\overline{k}, a\right)},\overline f, i\right)
      &\triangleq& \overline{k_i} = \overline f \wedge \bigwedge_{0<j<i} \overline k \neq \overline f\\
      \allmiss\left(\tau,s\right) &\triangleq& \bigwedge_{\left(\overline k, a\right) \in \tau(s)} \overline k \neq \overline f
    \end{array}
  \]
  \caption{Weakest Precondition for pipelines}
  \label{fig:table-wp}
\end{figure}

The CEGIS algorithm relies on a way to generate boolean formulae that
capture the behavior of the programs. As in the standard CEGIS
approach, we compute the weakest precondition of a symbolic packet to
denote the input-output relation denoted by the command. However, just
as in the denotational semantics, we need a table instantation in
order to describe the behavior of tables. In previous work~\cite{pv4},
tables have been implemented as a n-ary nondeterministic demonic
choice between the actions. While this certainly covers all possible
behaviors of the table, it throws away information about the keys --
which is necessary knowledge for our synthesis problem.

Unlike~\cite{p4v}, we are doing our verification and synthesis with
our table instances $\tau$ in hand, which gives us the power to
describe more precisely the behavior of tables in our logical
formulae. This is captured in the function $\wp_\tau(c, \phi)$
described in Figure~\ref{fig:table-wp}. When we compute the weakest
precondition of table $t = (s, \overline f, \overline c, c_0)$ of a
formula $\phi$ with respect to an instantiation
$\tau(s) = (\overline{k_1}, a_1), \ldots, (\overline{k_n}, a_n)$, we
separately compute the condition $\hit(\tau, s, i)$ under which each
entry $i$, and the weakest precondition of executing that action
$\wp_\tau(c_{a_i}, \phi)$. Then we intersect
$\hit(\tau, s, i) \Rightarrow \wp(c_{a_i}, \phi)$ for every $i$. Then
for the default action, we compute $\allmiss(\tau, s)$, which just
negates the match condition of every entry, as the guard for
$\wp_\tau(c_i, \phi)$.

The predicate $\hit(\tau, s, i)$ must be true if entry $i$ is hit.
The entry will be hit iff the the keys match
$(\overline{k_i} = \overline f)$ and if none of the previous keys do
$\bigwedge_{j<i}\overline {k_j} \neq \overline f$. So
$\hit(\tau, s, i)$ is just the conjunct of these two predicates.

The predicate $\allmiss(\tau, s , i)$ could be defined as
$\bigwedge_i \neg(\hit(\tau, s, i))$, but we can define it
equivalently, and much more simply as
$\bigwedge_i \overline {k_i} \neq \overline f$.


\subsection{Incremental Synthesis}

The monolithic Sketching alorithm was designed for general-purpose
programs, and as such, is designed to be run once, in an offline
fashion, to statically synthesize a performant program. A direct port
of this algorithm will try to recompute all of physical rules in the
logical program upon every rule insertion. To witness this, imagine
the controller executes a sequence of rules insertions
$e_1,\ldots, e_n$, which corresponds to a sequence of logical table
instantiation functions $\tau_1, \ldots, \tau_n$. Then, the monolithic
CEGIS algorithm will synthesize a corresponding sequence of physical
table instantiations $\tau_1', \ldots, \tau_n'$.

This seems wasteful. Each $\tau_{i+1} = \tau_i + e_{i+1}$, and as
defined, an insertion can only append a single rule to the bottom of a
single table. And in many cases $\tau_{i+1} = \tau_i +
\overline{e'}$. Why not leverage the fact that we already had two
instatiation functions that induced equivalent functions? All we need
to do is synthesize the deltas!

\todo[inline]{describe translation here or in earlier CEGIS Section}

Instead of asking the CEGIS loop to recompute every insertion in
$\tau_i$, we can ask it to only compute the sequence of additions in
$\overline{e}$. Instead of instrumenting the physical program with a
completely blank slate, we use the previous $\tau'$ and only add holes
necessary to compute the insertions. We insert 3 categories of holes
into each table $(s, \overline f, \overline c, c_0)$:
\begin{itemize}
\item (Necessity) Add a binary hole $\mathit{?AddTo}_s$ that is true
  when we need to insert a rule into that table
\item (Action Choice) For every action, add a sequence of guards
  $\mathit{?Act}_s = i$, following the command $c_i$.
\item (Keys) For each key $f_i$, add holes $\mathit{?f}_i$.
\end{itemize}

Together these three holes correspond to a new row in the select
corresponding\todo{define this somewhere!} to table $s$ of the form
\[
  \begin{array}l
    \overline{f} = \overline{\mathit{?f}} \wedge \mathit{?AddTo}_s = 1
    \to \left(\begin{array}l \IF \\
          \qquad \mathit{?Act}_s = 1 \to c_1 \\
          \qquad \cdots\\
          \qquad \mathit{?Act}_s = n \to c_n \\
          \ENDIF
        \end{array} \right)
  \end{array}
\]

This way, when z3 gives us a model for these holes, we know that we
must insert a rule into every table $s$ for which corresponding to
$\mathit{?AddTo}_s$ is true, and that rule will have the form
$(\overline{\mathit{?f}}, \mathit{?Act}_s)$.

\todo[inline]{example}

\todo[inline]{Conflict step!}

\subsection{Optimizations}
\begin{itemize}
\item Get models using paths
\item Candidate map
\item generalizing counter examples for range queries
\item caching rule templates
\item Linear-size VCs
\end{itemize}

\subsection{Abduction}
\begin{itemize}
\item cross-product examination of paths
\item Dataflow analysis
\end{itemize}

\subsection{Theoretical Results}
\begin{itemize}
\item Soundness
\item Completeness of Synthesis
\item Completeness of Abduction
\end{itemize}

\section{Implementation}
\todo[inline]{Describe the Implementation}XS
\begin{itemize}
\item P4 $\to$ Pipeline (including ternary explosion)
\item Pipeline + Instance $\to$  GCL
\end{itemize}

\subsection{Limitations}
\begin{itemize}
\item equivalent parsers
\item registers
\item worst-case blowup from ternary
\end{itemize}

\section{Evaluation}
\todo[inline]{Describe the experimental setup and analyze results}
\subsection{Real World Examples from ONF's Trellis}
\subsection{Synthetic Examples}
\subsection{Benchmark Abduction}

\section{Related Work}
\todo[inline]{Write Related Work} \todo[inline]{Sketch, p4v, Synthesis
  for P4, domino, panopticon, control plane stuff for openflow}
\todo[inline]{other synthesis stuff?}

\section{Conclusion}
\todo[inline]{Write Conclusion}

